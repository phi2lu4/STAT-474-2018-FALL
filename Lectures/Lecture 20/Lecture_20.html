<!DOCTYPE html>
<html>
  <head>
    <title>STAT 474 – Techniques for Large Data Sets</title>
    <meta charset="utf-8">
    <meta name="date" content="2018-10-15" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# STAT 474 – Techniques for Large Data Sets
## Fall 2018
### October 15, 2018

---




# SparklyR - Brief review


What is Spark?

- A new, faster, and more advanced engine for Big Data Analytics

- An attractive alternative to Hadoop due to its faster performance
  
- Spark is a cluster computing system and not a data storage system.

--

What is SparklyR?

- A brand new package from RStudio to interact with Spark

- *Under the hood:* SparklyR uses `dplyr` to interact with R users and Spark SQL to interact with Spark.

- SparklyR provides the access to Spark ML library to perform statistical and machine learning modeling on large data.

---
# In-class Activities

- Let's open RStudio and connect with your local Spark installed on Friday's lab.

- Let's take a look at the Web UI of Spark

- Tuning Spark requires expertise. Two basic parameters regarding the memory usage:


```r
conf &lt;- spark_config()
*conf$`sparklyr.shell.driver-memory` &lt;- "512M"
*conf$spark.memory.fraction &lt;- 0.8
```

---
# Working with large data sets

- American Statistical Association held a challenges in 2009 about [Airline on-time performance](http://stat-computing.org/dataexpo/2009/)

- Available data: All domestic flights from 1987-2008. We will only work with 2007-2008 data sets.


```r
if(!file.exists("2008.csv.bz2"))
  {download.file("http://stat-computing.org/dataexpo/2009/2008.csv.bz2", "2008.csv.bz2")}
if(!file.exists("2007.csv.bz2"))
  {download.file("http://stat-computing.org/dataexpo/2009/2007.csv.bz2", "2007.csv.bz2")}
```

---
# Read CSV files into Spark


```r
spark_read_csv(sc, "flights_spark_2008", "2008.csv.bz2", memory = FALSE)
```

--

- The `memory` argument controls if the data will be loaded into memory or kept on disk.

- Keeping data in memory makes computation much faster.

- **To Do:** take a look at Spark Web UI tabs. Any comment?
---
# Handler of Spark data sets

- The function `tbl()` provides access to data sets in Spark


```r
sp_flights &lt;- tbl(sc, "flight_spark_2008")
```

- Handler can be thought as the SQL script to query data from Spark


```r
object.size(sp_flights)
sp_flights %&gt;% show_query()
```

---
# Spark SQL

- Spark SQL can be accessed using SQL query thanks to the `DBI` package


```r
dbGetQuery(sc, "SELECT * FROM flights_spark_2008 LIMIT 10");
```

- Equivalently,


```r
sp_flights %&gt;% head(10)
```

- **To Do:** Extract the first 5 flights from Atlanta (`Origin == "ATL"`). What are those destinations?

---
# dplyr in SparklyR

- SparklyR converts `dplyr`-style query into SQL query before passing to Spark.

- Example:


```r
flights_table &lt;- sp_flights %&gt;%
    mutate(DepDelay = as.numeric(DepDelay),
         ArrDelay = as.numeric(ArrDelay),
         DepDelay &gt; 15 , DepDelay &lt; 240,
         ArrDelay &gt; -60 , ArrDelay &lt; 360, 
         Gain = DepDelay - ArrDelay) %&gt;%
  filter(ArrDelay &gt; 0) %&gt;%
  select(Origin, Dest, UniqueCarrier, Distance, DepDelay, ArrDelay, Gain)
  
  flights_table %&gt;% show_query()
```

- **Question:** What does the query do?

---
# Understand Caching

- When calling `flights_table`, Spark executes the query and return the results to the screen without saving it.

- `sdf_register()` will register the resulting in Spark (will see when calling `src_tbls()`)

- To drop a table, use `db_drop_table()`

--

- The `tbl_cache()` command loads the results into an Spark RDD in memory, so any analysis from there on will not need to re-read and re-transform the original file.

---
# Activity

- Compare the performance between cache versus uncache data: compute the number of rows in the `flights_table`


```r
flights_table %&gt;% tally()
```

- Using the following code to measure the running time:


```r
start_time &lt;- Sys.time()
&lt;Thing must be done in R&gt;
end_time &lt;- Sys.time()

end_time - start_time
```

---
# Activity

- Run:


```r
spark_read_csv(sc, "flights_spark_2007" , "2007.csv.bz2", memory = FALSE)
all_flights &lt;- tbl(sc, "flights_spark_2008") %&gt;%
  union(tbl(sc, "flights_spark_2007")) %&gt;%
  group_by(Year, Month) %&gt;%
  tally()
```

- **Question:** Are there more flights in 2008 than in 2007?

---
# Modeling in Sparkly R

- See demo.

- Cheat sheets about `sparklyr` and more can be downloaded at [RStudio Cheat Sheets](https://www.rstudio.com/resources/cheatsheets/)

---
class: middle, center

# Web Technologies
## Getting Data from the Web

---
# Web Scrapping

- Data and information on the web is growing exponentially.

- Web scraping is a technique for converting the data present in unstructured format (HTML tags) over the web to the structured format which can easily be accessed and used.

- Ways to scrap data:

  1. Human Copy-Paste
  
  2. Text pattern matching
  
  3. API Interface
  
  4. DOM Parsing
---
# Simple Web Scrapping with R - rvest package

- Loads tables from web pages

  - Looks for `&lt;table&gt;&lt;/table&gt;`
  
  - Table needs to be **well formatted**
  
  - Returns a *list* of *DataFrames*
  
- Can load *directly from URL*

  - Careful! Data changes. Save a copy with your analysis
  
- You will often need to do additional transformations to perpare the data.
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
